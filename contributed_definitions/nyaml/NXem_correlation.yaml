category: base
doc: |
  Base class to combine different method-specific data in electron microscopy.
  
  This base class represent a template for documenting correlations
  (spatial, temporal) between different method-specific results.
type: group
NXem_correlation(NXem_method):
  (NXprocess):
    doc: |
      Details about processing steps.
    sequence_index(NX_INT):
  indexing(NXprocess):
    doc: |
      Details about correlated or logically connected EBSD datasets.
      
      One important class of such correlated experiments are the so-called
      (quasi) in-situ experiments. In this case the same or nearly the same ROI
      gets analyzed via a repetitive sequence of thermomechanical treatment,
      sample preparation, measurement, on-the-fly-indexing. Phenomena
      investigated are recrystallization, strain accumulation, material damage.
      Post-processing is required to correlate and reidentify eventual
      microstructural features or local ROIs across several orientation maps.
      
      Another important class of correlated experiments are the so-called
      serial-sectioning experiments. Here the same sample is measured
      repetitively after polishing each time, to create a stack of
      orientation data which can be reconstructed to a
      three-dimensional volume ROI.
      
      Data can be correlated in time, position (spatial), or both (spatiotemporal).
      
      Spatial correlations between repetitively characterized regions-of-interests
      are typically correlated using image registration and alignment algorithms.
      For this typically so-called landmarks are used. These can be grains with
      a very large size or specific shape, i.e. grains which are qualitatively
      different enough to be used as a guide how images are shifted relative to
      one another. Other commonly used landmarks are fiducial marks which are
      milled into the specimen surface using focus-ion beam milling and/or various
      types of indentation methods.
      
      As far as the same physical region-of-interest is just measured several times,
      the additional issue of the depth increment is not a concern. However, correct
      assumptions for the depth increment, amount of material removed along the milling
      direction is relevant for accurate and precise three-dimensional (serial-sectioning)
      correlations. For these studies it can be tricky though to assume or estimate
      useful depth increments. Different strategies have been proposed like
      calibrations, wedged-shaped landmarks and computer simulation assisted
      assumption making.
      
      Despite the use of landmarks, there are many practical issues which make the
      processing of correlations imprecise and inaccurate. Among these are drift
      and shift of the specimen, instabilities of the holder, the beam, irrespective
      of the source of the drift, charging effects, here specifically causing local
      image distortions and rotations which may require special processing algorithms
      to reduce such imprecisions.
      
      Time correlations face all of the above-mentioned issues surplus the challenge
      that specific experimental protocols have to be used to ensure the material state
      is observed at specific physical time. The example of quasi in-situ characterization
      of crystal growth phenomena, a common topic in engineering or modern catalysis research
      makes it necessary to consider that e.g. the target value for the desired annealing
      temperature is not just gauged based on macroscopic arguments but considers
      that transient effects take place. Heating or quenching a sample might thus might
      not have been executed under conditions in the interaction volume as they are
      documented and/or assumed.
      
      These issue cause that correlations have an error margin as to how accurately
      respective datasets were not only just synced based on the geometry of the
      region-of-interests and the time markers but also to asssure which physical
      conditions the specimen experienced over the course of the measurements.
      
      The fourth example of the em_om reference implementation explores the use of the
      correlation group with a serial-sectioning datasets that was collected by the
      classical Inconel 100 dataset collected by M. D. Uchic and colleagues
      (M. Groeber M, Haley BK, Uchic MD, Dimiduk DM, Ghosh S 3d reconstruction and
      characterization of polycrystalline microstructures using a fib-sem system data set.
      Mater Charac 2006, 57 259â€“273. 10.1016/j.matchar.2006.01.019M).
      
      This dataset was specifically relevant in driving forward the implementation
      of the DREAM.3D software. DREAM.3D is an open-source software project for
      post-processing and reconstructing, i.e. correlating sets of orientation
      microscopy data foremost spatially. One focus of the software is the
      (post-)processing of EBSD datasets. Another cutting edge tool with similar
      scope but a commercial solution by Bruker is QUBE which was developed by
      P. Konijnenberg and coworkers.
      
      Conceptually, software like DREAM.3D supports users with creating linear
      workflows of post-processing tasks. Workflows can be instructed via the
      graphical user interface or via so-called pipeline processing via command line
      calls. DREAM.3D is especially useful because its internal system documents all
      input, output, and parameter of the processing steps. This makes DREAM.3D a
      good candidate to interface with tools like em_om parser. Specifically, DREAM.3D
      documents numerical results via a customized HDF5 file format called DREAM3D.
      Workflow steps and settings are stored as nested dictionaries in JSON syntax
      inside a supplementary JSON file or alongside the data in the DREAM3D file.
      DREAM.3D has a few hundred algorithms implemented. These are called filters
      in DREAM.3D terminology.
      
      Users configure a workflow which instructs DREAM.3D to send the data through
      a chain of predefined and configured filters. Given that for each analysis
      the filter is documented via its version tags surplus its parameter and setting
      via a controlled vocabulary, interpreting the content of a DREAM3D HDF5 file
      is possible in an automated manner using a parser. This makes DREAM.3D analyses
      repeatable and self-descriptive. A key limitation though is that most frequently
      the initial set of input data come from commercial files like ANG.
      This missing link between the provenance of these input files, their associated
      creation as electron microscope session, is also what NXem_ebsd solves.
      
      Nevertheless, as this can be solved with e.g. NXem_ebsd we are convinced that
      the DREAM.3D and the em_om parser can work productively together to realize
      RDMS-agnostic parsing of serial-section analyses.
      
      The internal documentation of the DREAM.3D workflow also simplifies the
      provenance tracking represented by an instance of NXem_ebsd as not every
      intermediate results has to be stored. Therefore, the fourth example
      focuses on the key result obtained from DREAM.3D - the reconstructed
      and aligned three-dimensional orientation map.
      
      Usually, this result is the starting point for further post-processing
      and characterization of structural features. As here orientation microscopy
      is insofar scale invariant using DREAM.3D, NXem_ebsd, and em_om should
      be useful for different characterization methods, such as EBSD, Transmission
      Kikuchi Diffraction (TKD), Automated Crystal Orientation Mapping (ACOM),
      Nanobeam Electron Diffraction (using commercial systems like NanoMegas ASTAR)
      or open-source implementations of these techniques (such as via pyxem/orix).
      
      The result of orientation microscopy methods are maps of local orientation
      and thermodynamic phase (crystal structure) pieces of information. Virtually
      all post-processing of such results for structural features includes again
      a workflow of steps which are covered though by the NXms partner application
      definition. The respective source of the data in an instance of NXms can
      again be a link or reference to an instance of NXem_ebsd to complete the
      chain of provenance.
    (NXcrystal_structure):
    roi(NXdata):
      descriptor:
        doc: |
          Descriptor representing the image contrast.
      # \@signal:  # data
      # \@axes:  # [axis_y, axis_x]
      # \@axis_x_indices: 0
      # \@axis_y_indices: 1
      # \@signal:
      # \@axes:
      # \@AXISNAME_indices:
      # \@long_name:
      title:
        doc: |
          Title of the default plot.
      data(NX_NUMBER):
        unit: NX_UNITLESS
        doc: |
          Descriptor values displaying the ROI.
        dim: (n_z, n_y, n_x)
        # n_0 slowest 3, n_1 slow 2, n_2 fast 1, rgb triplet is fastest 0
        # in axes fast to fastest
        # while for _indices fastest to fast
        \@long_name:
          doc: |
            Descriptor values.
      axis_z(NX_NUMBER):
        unit: NX_LENGTH
        doc: |
          Calibrated coordinate along the z-axis.
        dim: (n_z,)
        \@long_name:
          doc: |
            Label for the z axis
      axis_y(NX_NUMBER):
        unit: NX_LENGTH
        doc: |
          Calibrated coordinate along the y-axis.
        dim: (n_y,)
        \@long_name:
          doc: |
            Label for the y axis
      axis_x(NX_NUMBER):
        unit: NX_LENGTH
        doc: |
          Calibrated coordinate along the x-axis.
        dim: (n_x,)
        \@long_name:
          doc: |
            Label for the x axis
    # NEW ISSUE: implement support for filters eventually many of them
    # NEW ISSUE: for now only show that data from DREAM3D can be loaded.
    # NEW ISSUE: how to handle landmarks
    # NEW ISSUE: again an entire set of workflows such as rigid or non-rigid
    # image registration etc.
    # sequence_index(N0):
